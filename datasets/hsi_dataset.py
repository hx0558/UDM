import numpy as np
from pathlib import Path
from typing import Callable, Optional, Dict

import scipy.io as sio

import torch
from torch import from_numpy as fn
from torch.utils.data import TensorDataset
from torchvision.datasets import VisionDataset
import torchvision
import random

dataset_types = ('train', 'val', 'test')


# class CachedHSIDataset(VisionDataset):
#     """
#     Args:
#         data_path (pathlib.Path/str): File path of the HSI data.
#         gt_path (pathlib.Path/str): File path of the HSI gt.
#         transform (callable, optional): A function/transform that takes in an PIL image
#             and returns a transformed version. E.g, ``transforms.RandomCrop``
#         target_transform (callable, optional): A function/transform that takes in the
#             target and transforms it.
#     """
#
#     def __init__(
#             self,
#             data_path: 'Path, str',
#             gt_path: 'Path, str',
#             transform: Optional[Callable] = None,
#             target_transform: Optional[Callable] = None,
#     ):
#
#         self.data_path = data_path if isinstance(data_path, Path) else Path(data_path)
#         self.gt_path = gt_path if isinstance(gt_path, Path) else Path(gt_path)
#
#         super(CachedHSIDataset, self).__init__(
#             str(self.data_path.parent), transform=transform,
#             target_transform=target_transform)
#
#         imgs = torch.tensor(np.load(str(self.data_path)))
#         anns = torch.tensor(np.load(str(self.gt_path)))
#
#         self.dataset = TensorDataset(imgs, anns)
#
#     def __getitem__(self, idx):
#         img, target = self.dataset[idx]
#
#         if self.transform is not None:
#             img = self.transform(img)
#
#         if self.target_transform is not None:
#             target = self.target_transform(target)
#
#         return img, target
#
#     def __len__(self) -> int:
#         return len(self.dataset)

#############################针对武汉数据集的
class CachedHSIDataset(VisionDataset):
    def __init__(
            self,
            data_path: 'Path, str',
            gt_path: 'Path, str',
            lidar_path: 'Path, str' = None,
            transform: Optional[Callable] = None,
            target_transform: Optional[Callable] = None,
    ):

        self.data_path = data_path if isinstance(data_path, Path) else Path(data_path)
        self.gt_path = gt_path if isinstance(gt_path, Path) else Path(gt_path)

        self.lidar_path = None
        if lidar_path is not None:
            self.lidar_path = lidar_path if isinstance(lidar_path, Path) else Path(lidar_path)

        super(CachedHSIDataset, self).__init__(
            str(self.data_path.parent), transform=transform,
            target_transform=target_transform)

        # 【关键修改】：添加 mmap_mode='r'
        # 这样加载 150GB 的文件几乎不耗内存，只在 __getitem__ 取数据时才读硬盘
        self.imgs_mmap = np.load(str(self.data_path), mmap_mode='r')
        self.anns_mmap = np.load(str(self.gt_path), mmap_mode='r')

        if self.lidar_path is not None and self.lidar_path.exists():
            self.lidar_mmap = np.load(str(self.lidar_path), mmap_mode='r')
            self.has_lidar = True
        else:
            self.has_lidar = False

    def __getitem__(self, idx):
        # 从 mmap 中读取数据，此时数据被拷贝到内存 (只有这一个样本，不会OOM)
        # 可以在这里转 .float() / .long()
        img = torch.from_numpy(self.imgs_mmap[idx]).float()
        target = torch.tensor(self.anns_mmap[idx]).long()

        if self.has_lidar:
            lidar = torch.from_numpy(self.lidar_mmap[idx]).float()

            if self.transform is not None:
                img = self.transform(img)

            if self.target_transform is not None:
                target = self.target_transform(target)

            return img, lidar, target
        else:
            if self.transform is not None:
                img = self.transform(img)

            if self.target_transform is not None:
                target = self.target_transform(target)

            return img, target

    def __len__(self) -> int:
        # 使用 shape[0] 获取长度，不用加载整个数组
        return self.imgs_mmap.shape[0]

class HSIDataset(VisionDataset):
    """
    Args:
        data_path (pathlib.Path/str): File path of the HSI data.
        gt_path (pathlib.Path/str): File path of the HSI gt.
        info_path (pathlib.Path/str): File path of the split info generated by builder.
        dataset_type (str): train, val or test set.
        transform (callable, optional): A function/transform that takes in an PIL image
            and returns a transformed version. E.g, ``transforms.RandomCrop``
        target_transform (callable, optional): A function/transform that takes in the
            target and transforms it.
    """

    def __init__(self,
                 data_path_HSI: 'Path, str',
                 data_path_LiDAR: 'Path, str',
                 gt_path: 'Path, str',
                 info_path: 'Path, str',
                 dataset_type: str,
                 transform: Optional[Callable] = None,
                 target_transform: Optional[Callable] = None,):

        self.data_path_HSI = data_path_HSI if isinstance(data_path_HSI, Path) else Path(data_path_HSI)
        self.data_path_LiDAR = data_path_LiDAR if isinstance(data_path_LiDAR, Path) else Path(data_path_LiDAR)
        self.gt_path = gt_path if isinstance(gt_path, Path) else Path(gt_path)
        self.info_path = gt_path if isinstance(info_path, Path) else Path(info_path)

        transform = transform.get(dataset_type, None) \
            if isinstance(transform, Dict) else transform
        target_transform = target_transform.get(dataset_type, None) \
            if isinstance(target_transform, Dict) else target_transform

        super(HSIDataset, self).__init__(str(self.data_path_HSI.parent),
                                         transform=transform,
                                         target_transform=target_transform)
        # load split info
        info = sio.loadmat(info_path)
        self.coords = info['coords']
        self.RandPerm = info['RandPerm'].squeeze()
        self.window_size = info['window_size'].item()
        assert self.window_size % 2 == 1, ValueError(
            f"The window_size {self.window_size} ought "
            "to be a singular number")
        self.half_window = self.window_size // 2
        self.use_edge = info['use_edge'].item()
        self.train = info['train'].item()
        self.val = info['val'].item()

        self.indices = None
        assert dataset_type in dataset_types
        self.dataset_type = dataset_type

        # load meta data and gt
        data_HSI = {k: v for k, v in sio.loadmat(data_path_HSI).items()
                    if isinstance(v, np.ndarray)}
        data_LiDAR = {k: v for k, v in sio.loadmat(data_path_LiDAR).items()
                      if isinstance(v, np.ndarray)}
        gt = {k: v for k, v in sio.loadmat(gt_path).items()
                   if isinstance(v, np.ndarray) and 'map' not in k}
        assert len(data_HSI) == 1 and len(gt) == 1, \
            ValueError('Description Reading the MAT file conflicts.')

        data_HSI, data_LiDAR, gt = list(data_HSI.values())[0], list(data_LiDAR.values())[0], list(gt.values())[0]

        # pre-processing
        data_HSI = 1 * ((data_HSI - np.min(data_HSI)) / (np.max(data_HSI) - np.min(data_HSI)))  # 归一化方式改变
        data_LiDAR = 1 * ((data_LiDAR - np.min(data_LiDAR)) / (np.max(data_LiDAR) - np.min(data_LiDAR)))

        self.data_HSI = data_HSI.transpose([2, 0, 1])  # H, W, C --> C, H, W
        if len(data_LiDAR.shape) == 2:
            data_LiDAR = np.expand_dims(data_LiDAR, axis=2)
        self.data_LiDAR = data_LiDAR.transpose([2, 0, 1])
        self.gt = gt - 1

    @property
    def dataset_type(self):
        return self._dataset_type

    @dataset_type.setter
    def dataset_type(self, value):
        self._dataset_type = value
        train, val = self.train, self.val
        trainval = train + val
        # set base item
        if self.dataset_type == 'train':
            self.indices = self.RandPerm[:train]
        elif self.dataset_type == 'val':
            self.indices = self.RandPerm[train:trainval]
        else:
            self.indices = self.RandPerm[trainval:]

    def __getitem__(self, item):
        ind = self.indices[item]
        coord_x, coord_y = self.coords[ind]
        half_window = self.half_window

        half_window2=0
        img_HSI = fn(self.data_HSI[:,
                     coord_x - half_window: coord_x + half_window + 1,
                     coord_y - half_window: coord_y + half_window + 1
                     ].astype(np.float32))
        img_LiDAR = fn(self.data_LiDAR[:,
                       coord_x - half_window: coord_x + half_window + 1,
                       coord_y - half_window: coord_y + half_window + 1
                       ].astype(np.float32))

        target = self.gt[coord_x, coord_y].astype(np.int64)
        target = fn(np.array(target))

        if self.transform is not None:
            img_HSI = self.transform(img_HSI)
            img_LiDAR = self.transform(img_LiDAR)
        if self.target_transform is not None:
            target = self.target_transform(target)

        # if return_spectral:
        #     return img, target, img_spectral
        # else:
        return img_HSI, img_LiDAR, target,

    def __len__(self):
        return len(self.indices)